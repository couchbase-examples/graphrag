{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbw833Y2gckr"
   },
   "source": [
    "# Tutorial on GraphRAG with Couchbase\n",
    "This notebook walks through the process of setting up a search engine that combines Couchbase for storing embeddings, OpenAI's models for generating embeddings, and a local search engine for querying structured data. This is useful when you need to search through structured data using natural language queries, leveraging both machine learning and a database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaN5siuBgctS"
   },
   "source": [
    "# Importing Necessary Libraries\n",
    "In this section, we import all the essential Python libraries required to perform various tasks, such as loading data, interacting with Couchbase, and using OpenAI models for generating text and embeddings.\n",
    "\n",
    "The libraries used include:\n",
    "\n",
    "asyncio: For running asynchronous tasks.\n",
    "logging: For managing logs that help in debugging and monitoring the workflow.\n",
    "pandas: For data manipulation and reading from data files.\n",
    "tiktoken: For tokenizing text, which is essential for preparing text before passing it to a language model.\n",
    "graphrag.query and vector_stores: These are custom libraries that handle entity extraction, searching, and vector storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5tIHss5Rglye"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "import traceback\n",
    "from typing import Any, Callable, Dict, List, Union\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.input.loaders.dfs import store_entity_semantic_embeddings\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.embedding import OpenAIEmbedding\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.query.structured_search.local_search.search import LocalSearch\n",
    "from graphrag.vector_stores.couchbasedb import CouchbaseVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2efKWBqpgcw-"
   },
   "source": [
    "# Configuring Environment Variables\n",
    "Here, we configure various environment variables that define paths, API keys, and connection strings. These values are essential for connecting to Couchbase and OpenAI, loading data, and defining other constants.\n",
    "\n",
    "INPUT_DIR: This specifies where to find the data files.\n",
    "COUCHBASE_CONNECTION_STRING: Connection details for Couchbase.\n",
    "OPENAI_API_KEY: Your OpenAI API key, required for interacting with their models.\n",
    "LLM_MODEL: Specifies which OpenAI model to use (e.g., GPT-4).\n",
    "EMBEDDING_MODEL: Defines the model used to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Cz1PfM7zgc39"
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = os.getenv(\"INPUT_DIR\")\n",
    "COUCHBASE_CONNECTION_STRING = os.getenv(\"COUCHBASE_CONNECTION_STRING\", \"couchbase://localhost\")\n",
    "COUCHBASE_USERNAME = os.getenv(\"COUCHBASE_USERNAME\", \"Administrator\")\n",
    "COUCHBASE_PASSWORD = os.getenv(\"COUCHBASE_PASSWORD\", \"password\")\n",
    "COUCHBASE_BUCKET_NAME = os.getenv(\"COUCHBASE_BUCKET_NAME\", \"graphrag-demo\")\n",
    "COUCHBASE_SCOPE_NAME = os.getenv(\"COUCHBASE_SCOPE_NAME\", \"shared\")\n",
    "COUCHBASE_VECTOR_INDEX_NAME = os.getenv(\"COUCHBASE_VECTOR_INDEX_NAME\", \"grapghrag_index\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"gpt-4o\")\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\", \"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlnoR17Tgc7b"
   },
   "source": [
    "# Loading Data from Parquet Files\n",
    "In this part, we load data from Parquet files into a dictionary. Each file corresponds to a particular table in the dataset, and we define functions that will handle the loading and processing of each table.\n",
    "\n",
    "read_indexer_entities, read_indexer_relationships, etc., are custom functions responsible for reading specific parts of the data, such as entities and relationships.\n",
    "We use pandas to load the data from the files, and if a file is not found, we log a warning and continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QQTIbPrzgvyS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 15:34:48,630 - __main__ - INFO - Loading data from parquet files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 15:34:48,805 - __main__ - WARNING - COVARIATE_TABLE file not found. Setting covariates to None.\n",
      "2024-09-06 15:34:48,869 - __main__ - INFO - Data loading completed\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Loading data from parquet files\")\n",
    "data = {}\n",
    "\n",
    "# Constants\n",
    "COMMUNITY_LEVEL = 2\n",
    "\n",
    "# Table names\n",
    "TABLE_NAMES = {\n",
    "    \"COMMUNITY_REPORT_TABLE\": \"create_final_community_reports\",\n",
    "    \"ENTITY_TABLE\": \"create_final_nodes\",\n",
    "    \"ENTITY_EMBEDDING_TABLE\": \"create_final_entities\",\n",
    "    \"RELATIONSHIP_TABLE\": \"create_final_relationships\",\n",
    "    \"COVARIATE_TABLE\": \"create_final_covariates\",\n",
    "    \"TEXT_UNIT_TABLE\": \"create_final_text_units\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    data[\"entities\"] = pd.read_parquet(f\"{INPUT_DIR}/{TABLE_NAMES['ENTITY_TABLE']}.parquet\")\n",
    "    entity_embeddings = pd.read_parquet(f\"{INPUT_DIR}/{TABLE_NAMES['ENTITY_EMBEDDING_TABLE']}.parquet\")\n",
    "    data[\"entities\"] = read_indexer_entities(data[\"entities\"], entity_embeddings, COMMUNITY_LEVEL)\n",
    "except FileNotFoundError:\n",
    "    logger.warning(\"ENTITY_TABLE file not found. Setting entities to None.\")\n",
    "    data[\"entities\"] = None\n",
    "\n",
    "try:\n",
    "    data[\"relationships\"] = pd.read_parquet(f\"{INPUT_DIR}/{TABLE_NAMES['RELATIONSHIP_TABLE']}.parquet\")\n",
    "    data[\"relationships\"] = read_indexer_relationships(data[\"relationships\"])\n",
    "except FileNotFoundError:\n",
    "    logger.warning(\"RELATIONSHIP_TABLE file not found. Setting relationships to None.\")\n",
    "    data[\"relationships\"] = None\n",
    "\n",
    "try:\n",
    "    data[\"covariates\"] = pd.read_parquet(f\"{INPUT_DIR}/{TABLE_NAMES['COVARIATE_TABLE']}.parquet\")\n",
    "    data[\"covariates\"] = read_indexer_covariates(data[\"covariates\"])\n",
    "except FileNotFoundError:\n",
    "    logger.warning(\"COVARIATE_TABLE file not found. Setting covariates to None.\")\n",
    "    data[\"covariates\"] = None\n",
    "\n",
    "try:\n",
    "    data[\"reports\"] = pd.read_parquet(f\"{INPUT_DIR}/{TABLE_NAMES['COMMUNITY_REPORT_TABLE']}.parquet\")\n",
    "    entity_data = pd.read_parquet(f\"{INPUT_DIR}/{TABLE_NAMES['ENTITY_TABLE']}.parquet\")\n",
    "    data[\"reports\"] = read_indexer_reports(data[\"reports\"], entity_data, COMMUNITY_LEVEL)\n",
    "except FileNotFoundError:\n",
    "    logger.warning(\"COMMUNITY_REPORT_TABLE file not found. Setting reports to None.\")\n",
    "    data[\"reports\"] = None\n",
    "\n",
    "try:\n",
    "    data[\"text_units\"] = pd.read_parquet(f\"{INPUT_DIR}/{TABLE_NAMES['TEXT_UNIT_TABLE']}.parquet\")\n",
    "    data[\"text_units\"] = read_indexer_text_units(data[\"text_units\"])\n",
    "except FileNotFoundError:\n",
    "    logger.warning(\"TEXT_UNIT_TABLE file not found. Setting text_units to None.\")\n",
    "    data[\"text_units\"] = None\n",
    "\n",
    "logger.info(\"Data loading completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8AOUrIAgc-8"
   },
   "source": [
    "# Setting Up the Couchbase Vector Store\n",
    "Couchbase is used here to store the semantic embeddings generated from entities. In this step, we define a method to connect to the Couchbase database using the provided credentials.\n",
    "\n",
    "The CouchbaseVectorStore allows you to store, retrieve, and manage vector embeddings in Couchbase.\n",
    "The connect() method initializes the connection to Couchbase using the provided connection string, username, and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kiYpzj7-gdC4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 15:34:48,892 - __main__ - INFO - Setting up CouchbaseVectorStore\n",
      "2024-09-06 15:34:48,898 - graphrag.vector_stores.couchbasedb - INFO - Connecting to Couchbase at couchbase://localhost\n",
      "2024-09-06 15:34:48,966 - graphrag.vector_stores.couchbasedb - INFO - Successfully connected to Couchbase\n",
      "2024-09-06 15:34:48,970 - __main__ - INFO - CouchbaseVectorStore setup completed\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Setting up CouchbaseVectorStore\")\n",
    "\n",
    "try:\n",
    "    description_embedding_store = CouchbaseVectorStore(\n",
    "        collection_name=\"entity_description_embeddings\",\n",
    "        bucket_name=COUCHBASE_BUCKET_NAME,\n",
    "        scope_name=COUCHBASE_SCOPE_NAME,\n",
    "        index_name=COUCHBASE_VECTOR_INDEX_NAME,\n",
    "    )\n",
    "    description_embedding_store.connect(\n",
    "        connection_string=COUCHBASE_CONNECTION_STRING,\n",
    "        username=COUCHBASE_USERNAME,\n",
    "        password=COUCHBASE_PASSWORD,\n",
    "    )\n",
    "    logger.info(\"CouchbaseVectorStore setup completed\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error setting up CouchbaseVectorStore: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJZhrj5egdGt"
   },
   "source": [
    "# Setting Up Language Models\n",
    "In this section, we configure the language models using OpenAI’s API. We initialize:\n",
    "\n",
    "ChatOpenAI: This is the language model used to generate responses to natural language queries.\n",
    "OpenAIEmbedding: This is the model used to generate vector embeddings for text data.\n",
    "tiktoken: This tokenizer is used to split text into tokens, which are essential for sending data to the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "japySJrUgdOG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 15:34:48,984 - __main__ - INFO - Setting up LLM and embedding models\n",
      "2024-09-06 15:34:49,594 - __main__ - INFO - LLM and embedding models setup completed\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Setting up LLM and embedding models\")\n",
    "\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        model=LLM_MODEL,\n",
    "        api_type=OpenaiApiType.OpenAI,\n",
    "        max_retries=20,\n",
    "    )\n",
    "\n",
    "    token_encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    text_embedder = OpenAIEmbedding(\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        api_base=None,\n",
    "        api_type=OpenaiApiType.OpenAI,\n",
    "        model=EMBEDDING_MODEL,\n",
    "        deployment_name=EMBEDDING_MODEL,\n",
    "        max_retries=20,\n",
    "    )\n",
    "\n",
    "    logger.info(\"LLM and embedding models setup completed\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error setting up models: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r08V2NuugdSF"
   },
   "source": [
    "# Storing Embeddings in Couchbase\n",
    "After generating embeddings for the entities, we store them in Couchbase. We use the store_entity_semantic_embeddings function to store the embeddings.\n",
    "\n",
    "This method checks if the input is either a dictionary or a list and processes it accordingly.\n",
    "It uses the Couchbase vector store to save the embeddings, ensuring that entities have the proper 'id' attribute for storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "C1wV0RqrgdVl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 15:34:49,609 - __main__ - INFO - Storing entity embeddings\n",
      "2024-09-06 15:34:49,612 - graphrag.vector_stores.couchbasedb - INFO - Loading 96 documents into vector storage\n",
      "2024-09-06 15:34:49,998 - graphrag.vector_stores.couchbasedb - INFO - Successfully loaded 96 out of 96 documents\n",
      "2024-09-06 15:34:50,007 - __main__ - INFO - Entity semantic embeddings stored successfully\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Storing entity embeddings\")\n",
    "\n",
    "try:\n",
    "    entities_list = list(data[\"entities\"].values()) if isinstance(data[\"entities\"], dict) else data[\"entities\"]\n",
    "\n",
    "    store_entity_semantic_embeddings(\n",
    "        entities=entities_list, vectorstore=description_embedding_store\n",
    "    )\n",
    "    logger.info(\"Entity semantic embeddings stored successfully\")\n",
    "except AttributeError as e:\n",
    "    logger.error(f\"Error storing entity semantic embeddings: {str(e)}\")\n",
    "    logger.error(\"Ensure all entities have an 'id' attribute\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error storing entity semantic embeddings: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0LSSSJlgdZd"
   },
   "source": [
    "# Building the Search Engine\n",
    "Now that we have stored the embeddings and set up the models, we create the search engine. This step configures how queries will be processed, how much weight each entity or relationship will have, and how many entities or relationships will be retrieved in a query.\n",
    "\n",
    "## LocalSearch\n",
    "A local search engine that integrates with the language model and vector store to retrieve data.\n",
    "## LocalSearchMixedContext\n",
    "A context builder that combines different types of context (reports, entities, relationships) and prepares them for querying.\n",
    "python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8ZiML072gddQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 15:34:50,037 - __main__ - INFO - Creating search engine\n",
      "2024-09-06 15:34:50,042 - __main__ - INFO - Search engine created\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Creating search engine\")\n",
    "\n",
    "context_builder = LocalSearchMixedContext(\n",
    "    community_reports=data[\"reports\"],\n",
    "    text_units=data[\"text_units\"],\n",
    "    entities=data[\"entities\"],\n",
    "    relationships=data[\"relationships\"],\n",
    "    covariates=data[\"covariates\"],\n",
    "    entity_text_embeddings=description_embedding_store,\n",
    "    embedding_vectorstore_key=EntityVectorStoreKey.ID,\n",
    "    text_embedder=text_embedder,\n",
    "    token_encoder=token_encoder,\n",
    ")\n",
    "\n",
    "local_context_params = {\n",
    "    \"text_unit_prop\": 0.5,\n",
    "    \"community_prop\": 0.1,\n",
    "    \"conversation_history_max_turns\": 5,\n",
    "    \"conversation_history_user_turns_only\": True,\n",
    "    \"top_k_mapped_entities\": 10,\n",
    "    \"top_k_relationships\": 10,\n",
    "    \"include_entity_rank\": True,\n",
    "    \"include_relationship_weight\": True,\n",
    "    \"include_community_rank\": False,\n",
    "    \"return_candidate_context\": False,\n",
    "    \"embedding_vectorstore_key\": EntityVectorStoreKey.ID,\n",
    "    \"max_tokens\": 12_000,\n",
    "}\n",
    "\n",
    "llm_params = {\n",
    "    \"max_tokens\": 2_000,\n",
    "    \"temperature\": 0.0,\n",
    "}\n",
    "\n",
    "search_engine = LocalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    llm_params=llm_params,\n",
    "    context_builder_params=local_context_params,\n",
    "    response_type=\"multiple paragraphs\",\n",
    ")\n",
    "\n",
    "logger.info(\"Search engine created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "By8DVv-Igdg0"
   },
   "source": [
    "# Running a Query\n",
    "Finally, we run a query on the search engine. In this case, the query is \"Give me a summary about the story\". This simulates asking the search engine to summarize the entities and relationships stored in Couchbase.\n",
    "\n",
    "asearch: This is an asynchronous search function that takes a query and returns a response generated by the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1SvUSrIbgdkh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 15:34:50,067 - __main__ - INFO - Running query: 'Give me a summary about the story'\n",
      "2024-09-06 15:34:50,075 - graphrag.vector_stores.couchbasedb - INFO - Performing similarity search by text with k=20\n",
      "2024-09-06 15:34:50,606 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-06 15:34:50,617 - graphrag.vector_stores.couchbasedb - INFO - Performing similarity search by vector with k=20\n",
      "2024-09-06 15:34:50,628 - graphrag.vector_stores.couchbasedb - INFO - Found 20 results in similarity search by vector\n",
      "2024-09-06 15:34:50,636 - graphrag.query.context_builder.community_context - WARNING - Warning: No community records added when building community context.\n",
      "2024-09-06 15:34:50,757 - graphrag.query.structured_search.local_search.search - INFO - GENERATE ANSWER: 1725617090.0754764. QUERY: Give me a summary about the story\n",
      "2024-09-06 15:34:51,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-09-06 15:35:02,055 - __main__ - INFO - Query completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 'Give me a summary about the story'\n",
      "Answer: ## Summary of the Story\n",
      "\n",
      "### Introduction to the Mission\n",
      "\n",
      "The narrative centers around a team from the Paranormal Military Squad, tasked with a mission at the Dulce military base. This mission, known as Operation: Dulce, involves investigating and responding to an alien signal that has been detected. The team is composed of key figures such as Alex, Dr. Jordan Hayes, Taylor Cruz, and Sam Rivera, each bringing their unique skills and perspectives to the mission [Data: Entities (21, 47, 50, 68, 27, 4); Relationships (117, 56, 31, 88, 68, 50, 27, 4)].\n",
      "\n",
      "### The Setting and Initial Discoveries\n",
      "\n",
      "The story unfolds in the eerie and technologically advanced environment of the Dulce base. The team navigates through various locations within the base, including the server room, where they uncover critical information, and the crash site, where Dr. Jordan Hayes studies alien technology [Data: Entities (50, 44); Relationships (58, 54, 32, 8, 73, 136)]. The concrete hallway marks a significant threshold between the familiar world above and the strangeness beneath, symbolizing the transition into the unknown [Data: Entities (24); Relationships (158)].\n",
      "\n",
      "### The Cosmic Play and Human Involvement\n",
      "\n",
      "The narrative describes the human race as unwitting actors in a larger cosmic play, with Earth as the stage. This cosmic play involves the potential for interstellar diplomacy and the intricate process of deciphering alien signals, metaphorically referred to as the \"cosmic ballet\" by Dr. Jordan Hayes [Data: Entities (55, 57, 88); Relationships (197, 153, 35, 12, 79)]. The team feels a profound sense of responsibility as they stand on the precipice of making history by establishing intergalactic contact [Data: Entities (62, 81); Relationships (102, 138, 211)].\n",
      "\n",
      "### Key Interactions and Relationships\n",
      "\n",
      "Alex emerges as a key figure, displaying leadership and mentorship qualities as he navigates the complexities of the mission. His interactions with other team members, such as Dr. Jordan Hayes and Sam Rivera, highlight the blend of respect, skepticism, and camaraderie that defines their relationships [Data: Entities (47); Relationships (117, 56, 88, 196, 155, 183)]. Taylor Cruz, another significant member, provides strategic insights and maintains a commanding presence, though not without moments of vulnerability and respect for the gravity of their discoveries [Data: Entities (27); Relationships (31, 46, 43, 32, 148)].\n",
      "\n",
      "### The Interstellar Pas de Deux\n",
      "\n",
      "A central theme in the story is the \"interstellar pas de deux,\" a dance-like interaction between the team and the unknown extraterrestrial intelligence. This interaction is marked by attempts at communication and understanding, with the team interpreting signals and uncovering the intent behind the alien messages [Data: Entities (90); Relationships (122, 65, 22, 90, 46)]. The potential for interspecies communication and the broader implications of their discoveries are explored, emphasizing the delicate balance between curiosity and caution [Data: Relationships (199, 201, 205, 210)].\n",
      "\n",
      "### Conclusion and Legacy\n",
      "\n",
      "As the team delves deeper into the mission, they confront the existential implications of their discoveries. The narrative captures their collective resolve and the transformation of their roles from mere operatives to guardians of a threshold, poised to redefine humanity's place in the cosmos [Data: Sources (3, 7, 10, 1)]. The story concludes with the team standing on the brink of a new reality, their actions and decisions poised to make history and potentially alter the course of human knowledge and interstellar relations.\n",
      "\n",
      "In summary, the story of Operation: Dulce is a compelling blend of science fiction and human drama, exploring themes of discovery, responsibility, and the profound impact of first contact with an alien intelligence. The characters' interactions and the unfolding cosmic narrative create a rich tapestry of intrigue and anticipation.\n"
     ]
    }
   ],
   "source": [
    "question = \"Give me a summary about the story\"\n",
    "logger.info(f\"Running query: '{question}'\")\n",
    "\n",
    "try:\n",
    "    result = await search_engine.asearch(question)\n",
    "    print(f\"Question: '{question}'\")\n",
    "    print(f\"Answer: {result.response}\")\n",
    "    logger.info(\"Query completed successfully\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred while processing the query: {str(e)}\")\n",
    "    print(f\"An error occurred while processing the query: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wb4weYVBgdn_"
   },
   "source": [
    "With these steps, the entire process of loading data, setting up models, storing embeddings, and running a search engine query is written out in sequence without using functions. Let me know if any additional modifications are needed!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
